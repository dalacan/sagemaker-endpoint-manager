{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a auto start/stop Amazon SageMaker Foundation Model endpoint backed by a API Gateway/Lambda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will run through examples of managing your SageMaker endpoint with the endpoint manager functionality.\n",
    "\n",
    "We will also walkthrough an example on how to interact with the API gateway endpoint secured by a Lambda authoerizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your API gateway URL and auth token\n",
    "\n",
    "`https://<API_GATEWAY_ID>.execute-api.<REGION>.amazonaws.com/prod/`\n",
    "\n",
    "`'Authorization': '<YOUR_TOKEN>'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://<API_GATEWAY_ID>.execute-api.us-east-1.amazonaws.com/prod/'\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "    'Authorization': '<YOUR_TOKEN>',\n",
    "    # 'X-Amzn-SageMaker-Custom-Attributes': 'accept_eula=true' # Uncomment this line if you are using a llama2\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-time Endpoint Management Functions\n",
    "When you create your endpoint for the first time, it will initialize it with the default provision time in minutes. You can check the available time left on your endpoint by either querying a specific endpoint or get a list of endpoint.\n",
    "\n",
    "#### Querying time left for a specific endpoint\n",
    "\n",
    "You can check the time left for a specific endpoint by querying the `endpoint-expiry` api as part of the endpoint manager functionality and passing in the `EndpointName`. Below is an example on how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set endpoint you like to lookup\n",
    "endpoint_name = 'demo-Falcon40B-Endpoint'\n",
    "\n",
    "# Flan example\n",
    "# endpoint_name = 'demo-FlanT5-Endpoint'\n",
    "\n",
    "# endpoint_name = 'demo-LLama-Endpoint'\n",
    "\n",
    "# endpoint_name = 'demo-LLama2-Endpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url=f\"{url}/endpoint-expiry?EndpointName={endpoint_name}\", headers=headers)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying time left for all managed endpoints\n",
    "\n",
    "You can also get a list of managed endpoints and their respective time left. This can be done by using the `endpoint-expiry` api as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url=f\"{url}/endpoint-expiry\", headers=headers)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extending your real-time endpoint expiry time\n",
    "The managed endpoint API also provides you with the ability to extend the expiry date. Below is an example on how you can extend an endpoint by 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"EndpointName\": endpoint_name,\n",
    "    \"minutes\": 30\n",
    "}\n",
    "response = requests.post(url=f\"{url}/endpoint-expiry\", headers=headers, json=payload)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a new real-time endpoint\n",
    "With the endpoint management API, you can also add a new real-time endpoint with pre-existing Amazon SageMaker endpoint configurations.\n",
    "\n",
    "Note: You can use the endpoint manager for any model regardless if it is jumpstart or not as long as you have a define Amazon SageMaker endpoint configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_endpoint_name=\"\"\n",
    "new_endpoint_config_name=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"EndpointName\": new_endpoint_name,\n",
    "    \"EndpointConfigName\": new_endpoint_config_name,\n",
    "    \"minutes\": 30\n",
    "}\n",
    "response = requests.post(url=f\"{url}/endpoint-expiry\", headers=headers, json=payload)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with your endpoint via API gateway\n",
    "\n",
    "With the deploy API Gateway and model lambda, you can interact with your Amazon SageMaker endpoint through the internet via API Gateway. Below is an example on how to send your payload request to the falcon model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falcon example\n",
    "payload = {\n",
    "    \"inputs\": \"Write a program to compute factorial in python:\",\n",
    "    \"parameters\": {\"max_new_tokens\": 200}\n",
    "}\n",
    "\n",
    "# FLAN example\n",
    "# payload = {\n",
    "#     'text_inputs':'Write a program to compute factorial in python:', \n",
    "#     'max_length': 100, \n",
    "#     'temperature': 0.0, \n",
    "#     'seed': 321\n",
    "# }\n",
    "\n",
    "# open-llama example\n",
    "# payload = {\n",
    "#     \"text_inputs\": \"Building a website can be done in 10 simple steps:\",\n",
    "#     \"max_length\": 110,\n",
    "#     \"no_repeat_ngram_size\": 3,\n",
    "# }\n",
    "\n",
    "# llama-2 example\n",
    "# payload = {\n",
    "#         \"inputs\": \"Building a website can be done in 10 simple steps:\",\n",
    "#         \"parameters\" :\n",
    "#             {\n",
    "#                 \"max_new_tokens\": 110, \n",
    "#                 \"top_p\": 0.9, \n",
    "#                 \"temperature\" : 0.1\n",
    "#             }\n",
    "# }\n",
    "\n",
    "response = requests.post(url=f\"{url}/falcon\", headers=headers, json=payload)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronously interacting with your real-time endpoint via API Gateway\n",
    "\n",
    "In some instances, the real-time endpoint may take longer than 30 seconds to return a responses. Due to API gateway's 30 second timeout hard limit, an asynchronous approach will be required. The following code show you an example on how to asynchronously interactive with your real-time endpoint via two API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falcon example\n",
    "payload = {\n",
    "    \"endpointname\": endpoint_name,\n",
    "    \"body\": {\"inputs\": \"Write a program to compute factorial in python:\", \"parameters\": {\"max_new_tokens\": 200}}\n",
    "}\n",
    "\n",
    "response = requests.post(url=f\"{url}/startexecution\", headers=headers, json=payload)\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "\n",
    "# Get the execution arn\n",
    "executionArn = response.json().get('executionArn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload ={\n",
    "    \"executionArn\": executionArn\n",
    "}\n",
    "response = requests.post(url=f\"{url}/describeexecution\", headers=headers, json=payload)\n",
    "\n",
    "while 'RUNNING' in response.json().get('status'):\n",
    "    time.sleep(1)\n",
    "    response = requests.post(url=f\"{url}/describeexecution\", headers=headers, json=payload)\n",
    "    print(\"Step is still running...\")\n",
    "\n",
    "# Return results\n",
    "output = response.json().get('output')\n",
    "output_json = json.loads(output)\n",
    "body = json.loads(output_json['Body'])\n",
    "body[0]['generated_text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive with your endpoint via Langchain/APIGateway\n",
    "\n",
    "The deploy API can be used with the [Amazon API Gateway/Langchain](https://python.langchain.com/docs/ecosystem/integrations/amazon_api_gateway) integration.\n",
    "\n",
    "The following example will walk you through on how to interact with the API Gateway backed by a Lambda authorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain==0.0.238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AmazonAPIGateway\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AmazonAPIGateway(api_url=f\"{url}/falcon\", headers=headers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain LLM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.95,\n",
    "    \"do_sample\": False,\n",
    "    \"return_full_text\": True,\n",
    "    \"temperature\": 0.2,\n",
    "}\n",
    "\n",
    "prompt = \"what day comes after Friday?\"\n",
    "llm.model_kwargs = parameters\n",
    "llm(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain/APIGateway Agent Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_new_tokens\": 50,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 0.25,\n",
    "    \"do_sample\": False,\n",
    "    \"temperature\": 0.1,\n",
    "}\n",
    "\n",
    "llm.model_kwargs = parameters\n",
    "\n",
    "# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"python_repl\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Now let's test it out!\n",
    "agent.run(\"\"\"\n",
    "Write a Python script that prints \"Hello, world!\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
