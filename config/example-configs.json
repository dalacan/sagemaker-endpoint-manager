{
    "project_prefix": "demo",
    "region_name": "us-east-1",
    "ddb_auth_table_name": "AuthTable",
    "jumpstart_models" :[
        {
            "name" : "Falcon40BPublic",
            "model_id" : "huggingface-llm-falcon-40b-instruct-bf16",
            "inference_instance_count": 2,
            "inference_instance_type" : "ml.g5.12xlarge",
            "inference_type": "realtime",
            "public": true,
            "schedule": {
                "initial_provision_minutes": 90
            },
            "integration": {
                "type": "lambda",
                "properties": {
                    "lambda_src": "functions/falcon",
                    "api_resource_name": "falcon"
                }
            }
        },
        {
            "name" : "FlanT5lambda",
            "model_id" : "huggingface-text2text-flan-t5-xxl",
            "inference_instance_type" : "ml.g5.12xlarge",
            "inference_type": "realtime",
            "schedule": {
                "initial_provision_minutes": 90
            },
            "integration": {
                "type": "lambda",
                "properties": {
                    "lambda_src": "functions/flan",
                    "api_resource_name": "flan"
                }
            }
        },
        {
            "name" : "FlanT5api",
            "model_id" : "huggingface-text2text-flan-t5-xxl",
            "inference_instance_type" : "ml.g5.12xlarge",
            "inference_type": "realtime",
            "schedule": {
                "initial_provision_minutes": 90
            },
            "integration": {
                "type": "api",
                "properties": {
                    "api_resource_name": "flanapi"
                }
            }
        },
        {
            "name" : "FlanT5Async",
            "model_id" : "huggingface-text2text-flan-t5-xxl",
            "inference_instance_type" : "ml.g5.8xlarge",
            "inference_type": "async"
        },
        {
            "name" : "LlamaLambda",
            "model_id" : "meta-textgeneration-llama-2-70b-f",
            "inference_instance_count": 1,
            "inference_instance_type" : "ml.g5.48xlarge",
            "inference_type": "realtime",
            "public": true,
            "schedule": {
                "initial_provision_minutes": 90
            },
            "integration": {
                "type": "lambda",
                "properties": {
                    "lambda_src": "functions/falcon",
                    "api_resource_name": "llama"
                }
            }
        }
    ]
}
